name: Prepare AutoMQ Cluster

on:
  workflow_dispatch:
    inputs:
      cloud_provider:
        default: aws-cn
        required: true
        type: string
      streaming_provider:
        default: automq
        required: true
        type: string
      region:
        default: cn-northwest-1
        required: true
        type: string
      uninstall:
        default: false
        required: true
        type: boolean
      execute_benchmark:
        default: false
        required: true
        type: boolean

jobs:
  prepare_env:
    name: Prepare AWS Environment
    runs-on: ubuntu-latest
    environment:  ${{ inputs.cloud_provider }}
    steps:
      - name: Checkout Benchmark Code
        uses: actions/checkout@v3

      - name: Cache local Maven repository
        uses: actions/cache@v2
        with:
          path: ~/.m2/repository
          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-maven-

      - name: Fetch Latest Data
        run: |
          git pull origin main

      - name: Build Benchmark Code
        run: |
          mvn clean package -Dlicense.skip=true -Dcheckstyle.skip -DskipTests -Dspotless.check.skip

      - name: Apply Variables and Secrets for Shared Files
        run: |
          echo "current path is: $(pwd)"
          sed -i "s/\${AUTOMQ_ENVID}/${{ inputs.streaming_provider }}/g" "driver-nats/deploy/provision-nats-aws.tf"
          sed -i "s/\${AUTOMQ_ENVID}/${{ inputs.streaming_provider }}/g" "driver-pravega/deploy/provision-pravega-aws.tf"
          sed -i "s/\${AUTOMQ_ENVID}/${{ inputs.streaming_provider }}/g" "driver-automq/deploy/terraform-aws/provision-kafka-aws.tf"

      - name: Apply Variables and Secrets for Streaming Provider
        working-directory: driver-automq/deploy/terraform-aws
        ## Set AK/SK and terraform s3 backend info
        run: |
          echo "current path is: $(pwd)"
          sed -i "s/\${TF_BACKEND_BUCKET}/$TF_BACKEND_BUCKET/g" "$TF_FILENAME"
          TF_FILENAME=$TF_FILENAME
          sed -i "s/\${TF_BACKEND_KEY}/$TF_BACKEND_KEY/g" "$TF_FILENAME"
          sed -i "s/\${TF_BACKEND_REGION}/${{ inputs.region }}/g" "$TF_FILENAME"
          sed -i "s/\${AUTOMQ_ACCESS_KEY}/${{ secrets.AUTOMQ_ACCESS_KEY }}/g" "$TF_VAR_FILENAME"
          sed -i "s/\${AUTOMQ_SECRET_KEY}/${{ secrets.AUTOMQ_SECRET_KEY }}/g" "$TF_VAR_FILENAME"
        env:
          TF_BACKEND_BUCKET: ${{ secrets.TF_BACKEND_BUCKET }}
          TF_BACKEND_KEY: ${{ secrets.TF_BACKEND_KEY }}-${{ inputs.streaming_provider }}
          TF_FILENAME: provision-kafka-aws.tf
          TF_VAR_FILENAME: terraform-aws-cn.tfvars

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AUTOMQ_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AUTOMQ_SECRET_KEY }}
          aws-region: ${{ inputs.region }}

      - name: Setup SSH key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/automq_aws
          echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/automq_aws.pub
          chmod 600 ~/.ssh/automq_aws
          chmod 644 ~/.ssh/automq_aws.pub

      - name: Install python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Setup Infra Cost
        run: |
          # Downloads the CLI based on your OS/arch and puts it in /usr/local/bin
          curl -fsSL https://raw.githubusercontent.com/infracost/infracost/master/scripts/install.sh | sh
          infracost --version
          infracost configure set api_key ${{ secrets.INFRA_COST_API_KEY }}

      - name: AWS Cost Estimate
        run: |
          if [ "${{ inputs.streaming_provider }}" == "automq" ]; then
                echo "[INFO] Provider is AutoMQ"
                cd  driver-automq/deploy/terraform-aws
          fi
          infracost breakdown --path . >> /tmp/aws-cost.txt
          COST_DETAIL_FILE=/tmp/aws-cost.txt
          cat $COST_DETAIL_FILE

      - name: Read and extract costs from file
        id: extract_costs
        run: |
          python3 - <<'EOF'
          import re
          import os
          import sys
          
          with open('/tmp/aws-cost.txt', 'r') as file:
              output = file.read()
          
          print("File content:")
          print(output)
          
          pattern = re.compile(r'â”ƒ\s*main\s*â”ƒ\s*\$(\d+)\s*â”ƒ\s*\$(\d+)\s*â”ƒ\s*\$(\d+)\s*â”ƒ')
          match = pattern.search(output)
          
          print(f"Match: {match}")
          
          if match:
              baseline_cost = match.group(1)
              usage_cost = match.group(2)
              total_cost = match.group(3)
          
              print(f"Baseline cost: ${baseline_cost}")
              print(f"Usage cost: ${usage_cost}")
              print(f"Total cost: ${total_cost}")
          
              github_output = os.getenv('GITHUB_OUTPUT', 'output.txt')
              with open(github_output, 'a') as output_file:
                  output_file.write(f'baseline_cost={baseline_cost}\n')
                  output_file.write(f'usage_cost={usage_cost}\n')
                  output_file.write(f'total_cost={total_cost}\n')
          else:
              print("Can't extract cost info")
              sys.exit(1)  # è§¦å‘é”™è¯¯å¹¶é€€å‡º
          EOF


      - name: Output Costs
        run: |
          echo "Baseline cost: ${{ steps.extract_costs.outputs.baseline_cost }}"
          echo "Usage cost: ${{ steps.extract_costs.outputs.usage_cost }}"
          echo "Total cost: ${{ steps.extract_costs.outputs.total_cost }}"

      - name: Setup terraform
        uses: hashicorp/setup-terraform@v3

      - name: Initialize terraform
        working-directory: driver-automq/deploy/terraform-aws
        run: terraform init

      - name: Uninstall Cloud Infra
        working-directory: driver-automq/deploy/terraform-aws
        if: ${{ inputs.uninstall }}
        run: terraform destroy --auto-approve -var-file terraform-aws-cn.tfvars


      - name: Terraform Plan
        working-directory: driver-automq/deploy/terraform-aws
        run: terraform plan -var-file terraform-aws-cn.tfvars


      - name: Apply terraform
        working-directory: driver-automq/deploy/terraform-aws
        if: ${{ !inputs.uninstall }}
        run: terraform apply --auto-approve -var-file terraform-aws-cn.tfvars

      - name: Install ansible
        if: ${{ !inputs.uninstall && !inputs.execute_benchmark }}
        run: |
          python -m pip install --upgrade pip
          python -m pip install --user ansible
          python -m pip install --user jmespath

      - name: Download Latest AutoMQ TGZ File
        if: ${{ !inputs.uninstall && !inputs.execute_benchmark &&  inputs.streaming_provider == 'automq' }}
        run: |
          curl -L https://download.automq.com/community_edition/artifacts/automq-kafka-latest.tgz -o /tmp/automq-kafka-latest.tgz

      - name: Install AutoMQ Cluster
        working-directory: driver-automq/deploy
        ##todo support other streaming provider later
        if: ${{ !inputs.uninstall && !inputs.execute_benchmark && inputs.streaming_provider == 'automq' }}
        run: |
          ansible-playbook deploy.yaml -i terraform-aws/hosts.ini
          

      - name: Execute Benchmark
        working-directory: driver-automq/deploy/terraform-aws
        if: ${{ inputs.execute_benchmark }}
        run: |
          # Set up base SSH and SCP commands with common options
          SSH_BASE_CMD="ssh -o StrictHostKeyChecking=no -i ~/.ssh/automq_aws"
          SCP_BASE_CMD="scp -o StrictHostKeyChecking=no -i ~/.ssh/automq_aws"
          SSH_HOST="$(terraform output --raw user)@$(terraform output --raw client_ssh_host)"
          BENCHMARK_DIR="/opt/benchmark"
          
          # Delete old benchmark result files
          sudo rm -f /tmp/*.json
          $SSH_BASE_CMD $SSH_HOST "sudo rm -f $BENCHMARK_DIR/*.json"
          $SSH_BASE_CMD $SSH_HOST "sudo rm -f $BENCHMARK_DIR/benchmark-worker.log"
          
          # Execute the benchmark test
          $SSH_BASE_CMD $SSH_HOST "cd $BENCHMARK_DIR && sudo ./bin/benchmark -d ./driver-automq/driver.yaml ./driver-automq/workloads/fast-tail-read-500m.yaml"
          
          # Check if new result files have been generated
          TIMEOUT=7200  # 2-hour timeout
          ELAPSED=0
          CHECK_INTERVAL=5  # Check every 5 seconds
          
          while [ $ELAPSED -lt $TIMEOUT ]; do
            if $SSH_BASE_CMD $SSH_HOST "ls $BENCHMARK_DIR/*.json"; then
              echo "Benchmark results are ready."
              break
            else
              echo "Waiting for benchmark results..."
              sleep $CHECK_INTERVAL
              ELAPSED=$(($ELAPSED + $CHECK_INTERVAL))
            fi
          done
          
          if [ $ELAPSED -lt $TIMEOUT ]; then
            # Copy the result files to local directory when they exist
            $SCP_BASE_CMD $SSH_HOST:$BENCHMARK_DIR/*.json /tmp
            $SCP_BASE_CMD $SSH_HOST:$BENCHMARK_DIR/benchmark-worker.log /tmp
          else
            # Exit with an error message if the timeout is reached without results
            echo "Timeout waiting for benchmark results."
            exit 1
          fi


      - name: Output Benchmark Result
        if: ${{ inputs.execute_benchmark }}
        run: |
          sudo apt-get install jq
          JSON_FILE=$(ls /tmp/*.json | head -n 1)
          cat $JSON_FILE

      - name: Install python dependencies
        if: ${{ inputs.execute_benchmark }}
        run: |
            python -m pip install --upgrade pip
            pip install regex

      - name: Extract Information from Benchmark Worker Log
        if: ${{ inputs.execute_benchmark }}
        run: |
          python3 - <<'EOF'
          import re
          import json
          
          log_file_path = "/tmp/benchmark-worker.log"
          output_file_path = "/tmp/extracted_data"
          
          # Define regex patterns
          workload_pattern = r'Workloads:\s*\{(.*?)\}'
          kafka_benchmark_driver_pattern = r'\[.*?\] INFO Benchmark - Initialized Kafka benchmark driver with common config: .*? producer config:\s*\{(.*?)\},  consumer config:\s*\{(.*?)\}, topic config:\s*\{(.*?)\}, replicationFactor:\s*(\d+)'

          # Read log file
          with open(log_file_path, 'r') as file:
            log_content = file.read()
          
          # Extract workload information
          workload_match = re.search(workload_pattern, log_content, re.DOTALL)
          workload = workload_match.group(1) if workload_match else "Not found"
            
          # Extract KafkaBenchmarkDriver information
          kafka_benchmark_driver_match = re.search(kafka_benchmark_driver_pattern, log_content)
          if kafka_benchmark_driver_match:
            producer_config = kafka_benchmark_driver_match.group(1).strip()
            consumer_config = kafka_benchmark_driver_match.group(2).strip()
            topic_config = kafka_benchmark_driver_match.group(3).strip()
            replicationFactor = kafka_benchmark_driver_match.group(4).strip()
          else:
            producer_config = "Not found"
            consumer_config = "Not found"
            topic_config = "Not found"
            replicationFactor = "Not found"
          
          # Calculate average throughput
          throughput_pattern = r'WorkloadGenerator - Pub rate \d+\.\d+ msg/s \/ (\d+\.\d+) MB/s'
          throughput_matches = re.findall(throughput_pattern, log_content)
          average_throughput = sum(float(tp) for tp in throughput_matches) / len(throughput_matches) if throughput_matches else 0
            
          # Prepare data for output
          extracted_data = {
            "workload_config": workload,
            "producer_config": producer_config,
            "consumer_config": consumer_config,
            "topic_config": topic_config,
            "replication_factor": replicationFactor,
            "average_throughput": average_throughput
          }
  
          # Write to output file
          with open(output_file_path, 'w') as outfile:
            json.dump(extracted_data, outfile, indent=4)
        
          # Print the extracted data for verification
          print(json.dumps(extracted_data, indent=4))
          EOF
          
          cat /tmp/extracted_data

      - name: Generate Report in Issue
        uses: actions/github-script@v6
        if: ${{ inputs.execute_benchmark }}
        env:
          JSON_FILE_PATH: /tmp
          EXTRACTED_DATA_PATH: /tmp/extracted_data
          BASELINE_COST: ${{ steps.extract_costs.outputs.baseline_cost }}
          USAGE_COST: ${{ steps.extract_costs.outputs.usage_cost }}
          TOTAL_COST: ${{ steps.extract_costs.outputs.total_cost }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            const path = require('path');
            
            const issue_number = 2;  // Specify the issue number
            const directoryPath = process.env.JSON_FILE_PATH;
            const extractedDataPath = process.env.EXTRACTED_DATA_PATH;
            
            // Read the directory and find the first JSON file
            const files = fs.readdirSync(directoryPath).filter(file => file.endsWith('.json'));
            if (files.length === 0) {
              console.log("No JSON file found.");
              return;
            }
            const firstJsonFile = files[0];
            const filePath = path.join(directoryPath, firstJsonFile);
            
            // Read the content of the JSON file
            const jsonData = JSON.parse(fs.readFileSync(filePath, 'utf8'));

            // Extract specific fields
            const workload = jsonData.workload;
            const messageSize = jsonData.messageSize;
            const topics = jsonData.topics;
            const partitions = jsonData.partitions;
            const producersPerTopic = jsonData.producersPerTopic;
            const consumersPerTopic = jsonData.consumersPerTopic;
            
            // Extract latency metrics
            const latencyAvg = jsonData.aggregatedEndToEndLatencyAvg;
            const latency95pct = jsonData.aggregatedEndToEndLatency95pct;
            const latency99pct = jsonData.aggregatedEndToEndLatency99pct;
            const latency999pct = jsonData.aggregatedEndToEndLatency999pct;
            
            
            //process extracted data
            let extractedData = JSON.parse(fs.readFileSync(extractedDataPath, 'utf8'));
            extractedData.workload_config = extractedData.workload_config.replace(/\\n/g, '\n');
            console.log(extractedData);

            // Extract specific fields from benchmark log json and extracted data
            const {
              workload_config,
              producer_config,
              consumer_config,
              topic_config,
              replication_factor,
              average_throughput
            } = extractedData;
            
            // Costs are directly used from the steps
            const baselineCost = process.env.BASELINE_COST;
            const usageCost = process.env.USAGE_COST;
            const totalCost = process.env.TOTAL_COST;
            
            // Get current date and time
            const now = new Date();
            const currentDate = now.toISOString().split('T')[0];
            const currentTime = now.toTimeString().split(' ')[0];
            
            // Generate a Markdown formatted report
            const markdownReport = `
              ## AutoMQ Benchmark VS. Result ðŸš€
              **Report Generated:** ${currentDate} ${currentTime}
              **Workload:** ${workload}
              **Message Size:** ${messageSize} bytes
              **Topics:** ${topics}
              **Partitions:** ${partitions}
              **Producers per Topic:** ${producersPerTopic}
              **Consumers per Topic:** ${consumersPerTopic}
              
              **Configurations and Throughput:**
              **Workload Configuration:**
              \`\`\`json
              ${JSON.stringify(workload_config, null, 2)}
              \`\`\`
              **Producer Configuration:**
              \`\`\`json
              ${JSON.stringify(producer_config, null, 2)}
              \`\`\`
              **Consumer Configuration:**
              \`\`\`json
              ${JSON.stringify(consumer_config, null, 2)}
              \`\`\`
              **Topic Configuration:**
              \`\`\`json
              ${JSON.stringify(topic_config, null, 2)}
              \`\`\`
              **Replication Factor:**
              \`\`\`json
              ${JSON.stringify(replication_factor, null, 2)}
              \`\`\`
              **Average Throughput:** ${average_throughput} MB/s
              
              | Streaming System | E2E LatencyAvg(ms) | E2E P95 Latency(ms) | E2E P99 Latency(ms) | Baseline Cost | Usage Cost | Total Cost |
              | ---------------- | ------------------ | ------------------- | ------------------- | ------------- | ---------- | ---------- |
              | AutoMQ           | ${latencyAvg}      | ${latency95pct}     | ${latency99pct}     | $${baselineCost} | $${usageCost} | $${totalCost} |
            `;
      
            // Post the report as a comment to the specified issue
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issue_number,
              body: markdownReport
            });
